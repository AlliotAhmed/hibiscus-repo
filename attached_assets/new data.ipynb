{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1b63a3b-684e-44c9-b028-2e7bbf04ced4",
   "metadata": {},
   "source": [
    "###Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf054a8-1bf0-49da-a93e-79f04951db40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((480, 128, 128, 3), (480, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Paths\n",
    "data_dir = 'Hibiscus Dataset'\n",
    "categories = ['Healthy_leaf', 'Diseased_leaf']\n",
    "img_size = 128  # Resize all images to 128x128\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for category in categories:\n",
    "    path = os.path.join(data_dir, category)\n",
    "    class_num = categories.index(category)\n",
    "    for img in os.listdir(path):\n",
    "        try:\n",
    "            img_array = cv2.imread(os.path.join(path, img))\n",
    "            img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "            data.append(img_array)\n",
    "            labels.append(class_num)\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "\n",
    "# Convert to arrays\n",
    "X = np.array(data) / 255.0  # normalize\n",
    "y = to_categorical(labels)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7d558b-0dc7-439a-997f-180bdbc38b5c",
   "metadata": {},
   "source": [
    "builds the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1689bf53-e7a2-4a47-8523-49c745e1e561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57600</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,372,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57600\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m7,372,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,392,578</span> (28.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,392,578\u001b[0m (28.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,392,578</span> (28.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,392,578\u001b[0m (28.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "mymodel = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')  # 2 classes: Healthy, Diseased\n",
    "])\n",
    "\n",
    "mymodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "mymodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f83af-2fdf-4a26-8531-17c9d4740950",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6b71c50-626d-4fc6-bb58-54c72bb2cb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - accuracy: 0.6238 - loss: 1.2225 - val_accuracy: 0.9167 - val_loss: 0.2424\n",
      "Epoch 2/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.9532 - loss: 0.1612 - val_accuracy: 1.0000 - val_loss: 0.0372\n",
      "Epoch 3/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.9931 - loss: 0.0300 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 4/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 6.9509e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 7.2390e-04 - val_accuracy: 1.0000 - val_loss: 3.5668e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 2.0869e-04 - val_accuracy: 1.0000 - val_loss: 2.0209e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 2.3004e-04 - val_accuracy: 1.0000 - val_loss: 1.1643e-05\n",
      "Epoch 8/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 9.4907e-05 - val_accuracy: 1.0000 - val_loss: 1.3289e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 1.0175e-04 - val_accuracy: 1.0000 - val_loss: 1.7824e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 9.0500e-05 - val_accuracy: 1.0000 - val_loss: 1.1260e-05\n"
     ]
    }
   ],
   "source": [
    "history = mymodel.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e9d78ae-cbf5-4e8a-8b2a-131d192e720a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 140ms/step - accuracy: 0.9901 - loss: 0.0355 - val_accuracy: 1.0000 - val_loss: 3.1945e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.9802 - loss: 0.0347 - val_accuracy: 1.0000 - val_loss: 6.9450e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 4.2041e-05\n",
      "Epoch 4/15\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 8.7245e-04 - val_accuracy: 1.0000 - val_loss: 7.7559e-06\n",
      "Epoch 5/15\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 8.3087e-04 - val_accuracy: 1.0000 - val_loss: 5.8014e-06\n",
      "Epoch 6/15\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 2.3605e-04 - val_accuracy: 1.0000 - val_loss: 1.1822e-06\n",
      "Epoch 7/15\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 7.8007e-05 - val_accuracy: 1.0000 - val_loss: 4.4455e-07\n",
      "Epoch 8/15\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 3.3217e-05 - val_accuracy: 1.0000 - val_loss: 2.7070e-07\n",
      "Epoch 9/15\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 9.1428e-05 - val_accuracy: 1.0000 - val_loss: 4.3213e-07\n",
      "Epoch 10/15\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 1.0093e-04 - val_accuracy: 1.0000 - val_loss: 7.5126e-07\n",
      "Epoch 11/15\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 5.9516e-05 - val_accuracy: 1.0000 - val_loss: 3.0796e-07\n",
      "Epoch 12/15\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 5.7220e-05 - val_accuracy: 1.0000 - val_loss: 1.2418e-07\n",
      "Epoch 13/15\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 4.2122e-05 - val_accuracy: 1.0000 - val_loss: 1.0555e-07\n",
      "Epoch 14/15\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 2.7771e-04 - val_accuracy: 1.0000 - val_loss: 1.0117e-05\n",
      "Epoch 15/15\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 2.3874e-04 - val_accuracy: 1.0000 - val_loss: 5.3655e-06\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=20, zoom_range=0.2, horizontal_flip=True)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "history = mymodel.fit(datagen.flow(X_train, y_train, batch_size=32), \n",
    "                    epochs=15, \n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a7a705-4237-4a98-8088-9aef4af6a09e",
   "metadata": {},
   "source": [
    "evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7964e7be-5045-4896-8ebe-b2b6bab6b446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Healthy_leaf       1.00      1.00      1.00        47\n",
      "Diseased_leaf       1.00      1.00      1.00        49\n",
      "\n",
      "     accuracy                           1.00        96\n",
      "    macro avg       1.00      1.00      1.00        96\n",
      " weighted avg       1.00      1.00      1.00        96\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Predictions\n",
    "y_pred = mymodel.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=categories, yticklabels=categories)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_true, y_pred_classes, target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7edc4264-c949-4d64-bc4c-f996a8d53882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "mymodel.save('model/hibiscus_leaf_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d96d09b-3220-4a35-9f71-261d0d5ac270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2f81ff4a-17b1-4742-b59b-5eae969010f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "✅ Accuracy: 1.0000\n",
      "\n",
      "📂 Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "✅ Accuracy: 1.0000\n",
      "\n",
      "📂 Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "✅ Accuracy: 1.0000\n",
      "\n",
      "📂 Fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "✅ Accuracy: 1.0000\n",
      "\n",
      "📂 Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "✅ Accuracy: 1.0000\n",
      "\n",
      "🎯 Average Accuracy over 5 folds: 1.0000\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "X = np.array(X)  # Already normalized (0-1)\n",
    "y_int = np.argmax(y, axis=1)  # Convert one-hot back to int for skf.split\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y_int)):\n",
    "    print(f\"\\n📂 Fold {fold + 1}/{k}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Define model\n",
    "    mymodel = Sequential([\n",
    "        Conv2D(32, (3,3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    mymodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train model\n",
    "    mymodel.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true_classes = np.argmax(y_val, axis=1)\n",
    "    \n",
    "    acc = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    print(f\"✅ Accuracy: {acc:.4f}\")\n",
    "    accuracies.append(acc)\n",
    "\n",
    "print(f\"\\n🎯 Average Accuracy over {k} folds: {np.mean(accuracies):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cb121c-ed7a-472c-b4fd-382f8af765d8",
   "metadata": {},
   "source": [
    "mobile integration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "968e7c81-6fee-4bea-96e0-f01cabceea78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/pt/hhq91p6n4sd5ppffbbjhm2s40000gn/T/tmpn5qcr5di/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/pt/hhq91p6n4sd5ppffbbjhm2s40000gn/T/tmpn5qcr5di/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/pt/hhq91p6n4sd5ppffbbjhm2s40000gn/T/tmpn5qcr5di'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='input_layer_11')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  13334098000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13334100304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13334100112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13334101072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13334100880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13334101648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13334100688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13334100496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1743882452.449004 3859398 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1743882452.449870 3859398 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-04-06 01:17:32.451010: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/pt/hhq91p6n4sd5ppffbbjhm2s40000gn/T/tmpn5qcr5di\n",
      "2025-04-06 01:17:32.451440: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-04-06 01:17:32.451445: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/pt/hhq91p6n4sd5ppffbbjhm2s40000gn/T/tmpn5qcr5di\n",
      "2025-04-06 01:17:32.456375: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-04-06 01:17:32.531931: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/pt/hhq91p6n4sd5ppffbbjhm2s40000gn/T/tmpn5qcr5di\n",
      "2025-04-06 01:17:32.537804: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 86794 microseconds.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model('model/hibiscus_leaf_classifier.h5')\n",
    "\n",
    "# Convert to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "with open('model/hibiscus_leaf_classifier.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c82f27c-6c78-4abf-9d06-31ab0f14d507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/pt/hhq91p6n4sd5ppffbbjhm2s40000gn/T/tmp447_vk91/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/pt/hhq91p6n4sd5ppffbbjhm2s40000gn/T/tmp447_vk91/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/pt/hhq91p6n4sd5ppffbbjhm2s40000gn/T/tmp447_vk91'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='input_layer_11')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  13435916688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13435918800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13435922256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13435920912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13435921104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13435920144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13435921296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13435919760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "✅ TFLite model saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1743882476.628789 3859398 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1743882476.628814 3859398 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-04-06 01:17:56.628944: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/pt/hhq91p6n4sd5ppffbbjhm2s40000gn/T/tmp447_vk91\n",
      "2025-04-06 01:17:56.629329: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-04-06 01:17:56.629334: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/pt/hhq91p6n4sd5ppffbbjhm2s40000gn/T/tmp447_vk91\n",
      "2025-04-06 01:17:56.632200: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-04-06 01:17:56.676505: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/pt/hhq91p6n4sd5ppffbbjhm2s40000gn/T/tmp447_vk91\n",
      "2025-04-06 01:17:56.681612: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 52668 microseconds.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the .h5 model\n",
    "model = tf.keras.models.load_model('model/hibiscus_leaf_classifier.h5')\n",
    "\n",
    "# Create a converter\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Optional: Apply optimizations for mobile\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the .tflite file\n",
    "with open('hibiscus_leaf_classifier.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"✅ TFLite model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b713fc00-2b4e-406e-bd63-ff9c8457ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"/Users/alliotahmed/Documents/Project-mini(college)/assets/hibiscus_leaf_classifier.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Load labels\n",
    "with open(\"/Users/alliotahmed/Documents/Project-mini(college)/assets/label.txt\", \"r\") as f:\n",
    "    labels = [line.strip() for line in f.readlines()]\n",
    "\n",
    "def classify_image(image):\n",
    "    image = image.resize((128, 128))  # Resize to model input\n",
    "    img_array = np.expand_dims(np.array(image).astype(np.float32) / 255.0, axis=0)\n",
    "\n",
    "    interpreter.set_tensor(input_details[0]['index'], img_array)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    predictions = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "    top_class = np.argmax(predictions)\n",
    "    confidence = predictions[top_class]\n",
    "\n",
    "    return labels[top_class], confidence\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"🌿 Hibiscus Leaf Disease Classifier\")\n",
    "st.write(\"Upload a photo of a leaf to check if it's healthy or diseased.\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
    "    st.image(image, caption=\"Uploaded Leaf Image\", use_column_width=True)\n",
    "\n",
    "    with st.spinner(\"Classifying...\"):\n",
    "        label, confidence = classify_image(image)\n",
    "    \n",
    "    st.success(f\"Prediction: **{label}** ({confidence * 100:.2f}% confidence)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed8a721-63ad-4528-83be-2dc4366dda07",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream lit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
